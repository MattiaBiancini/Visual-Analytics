{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Analytics\n",
    "\n",
    "## Assignment 3\n",
    "\n",
    "**Instructor:** Dr. Marco D'Ambros  \n",
    "**TAs:** Carmen Armenti, Mattia Giannaccari\n",
    "\n",
    "**Contacts:** marco.dambros@usi.ch, carmen.armenti@usi.ch, mattia.giannaccari@usi.ch\n",
    "\n",
    "**Due Date:** May 16, 2025 @ 23:55\n",
    "\n",
    "---\n",
    "The goal of this assignment is to use **Spark (PySpark)** and **Polars** in Jupyter notebooks.  \n",
    "The files `trip_data.csv`, `trip_fare.csv`, and `nyc_boroughs.geojson` are available in the provided folder: [Assignment3-data](https://usi365-my.sharepoint.com/:f:/g/personal/armenc_usi_ch/Ejp7sb8QAMROoWe0XUDcAkMBoqUFk-w2Vgroup025NhAww?e=2I7SMC).\n",
    "\n",
    "You may clean the data as needed; however, please note that specific data cleaning steps will be required in **Exercise 5**. If you choose to clean the data before Exercise 5, make sure to retain the **original dataset** for use with the Polars exercises.\n",
    "\n",
    "- Use **Spark** to solve **Exercises 1–4**\n",
    "- Use **Polars** to solve **Exercises 5–8**\n",
    "\n",
    "You are encouraged to use [Spark window functions](https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-window.html) whenever appropriate.\n",
    "\n",
    "Please name your notebook file as `SurnameName_Assignment3.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: polars in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (1.27.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: bokeh in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (3.7.2)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from bokeh) (3.1.6)\n",
      "Requirement already satisfied: contourpy>=1.2 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from bokeh) (1.3.2)\n",
      "Requirement already satisfied: narwhals>=1.13 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from bokeh) (1.37.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from bokeh) (1.26.4)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from bokeh) (25.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from bokeh) (2.2.3)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from bokeh) (11.2.1)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from bokeh) (6.0.2)\n",
      "Requirement already satisfied: tornado>=6.2 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from bokeh) (6.4.2)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from bokeh) (2025.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from Jinja2>=2.9->bokeh) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from pandas>=1.2->bokeh) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from pandas>=1.2->bokeh) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from pandas>=1.2->bokeh) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.2->bokeh) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: geopandas in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from geopandas) (1.26.4)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from geopandas) (0.10.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from geopandas) (25.0)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from geopandas) (2.2.3)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from geopandas) (3.7.1)\n",
      "Requirement already satisfied: shapely>=2.0.0 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from geopandas) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2025.2)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from pyogrio>=0.7.2->geopandas) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: bokeh_sampledata in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (2024.2)\n",
      "Requirement already satisfied: icalendar in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from bokeh_sampledata) (6.1.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from bokeh_sampledata) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from pandas>=1.2->bokeh_sampledata) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from pandas>=1.2->bokeh_sampledata) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from pandas>=1.2->bokeh_sampledata) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from pandas>=1.2->bokeh_sampledata) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.2->bokeh_sampledata) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark\n",
    "%pip install polars\n",
    "%pip install bokeh\n",
    "%pip install geopandas\n",
    "%pip install bokeh_sampledata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Join the `trip_data` and `trip_fare` dataframes into one and consider only data on 2013-01-01. Please specify the number of rows obtained after joining the 2 datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to create a `SparkSession`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/06 22:50:07 WARN Utils: Your hostname, USILU-16210.local resolves to a loopback address: 127.0.0.1; using 192.168.43.129 instead (on interface en0)\n",
      "25/05/06 22:50:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/06 22:50:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 59528)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/VS-assignment3/lib/python3.12/socketserver.py\", line 318, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/anaconda3/envs/VS-assignment3/lib/python3.12/socketserver.py\", line 349, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/anaconda3/envs/VS-assignment3/lib/python3.12/socketserver.py\", line 362, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/anaconda3/envs/VS-assignment3/lib/python3.12/socketserver.py\", line 766, in __init__\n",
      "    self.handle()\n",
      "  File \"/opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 400)\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trip_data_df = spark.read.csv('./data/trip_data.csv', header=True, inferSchema=True)\n",
    "trip_fare_df = spark.read.csv('./data/trip_fare.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before joining the 2 dataframe I am going to filter the datas by the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- medallion: string (nullable = true)\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- vendor_id: string (nullable = true)\n",
      " |-- rate_code: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_time_in_secs: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_data_df = trip_data_df.select([col(c).alias(c.strip()) for c in trip_data_df.columns])\n",
    "trip_data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- medallion: string (nullable = true)\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- vendor_id: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- surcharge: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_fare_df = trip_fare_df.select([col(c).alias(c.strip()) for c in trip_fare_df.columns])\n",
    "trip_fare_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 2 temporal metric I am going to filter on both in order to avoid `pickup_datetime` being 2012-12-31 while `dropoff_datetime` is 2013-01-01 and in similar way I want to avoid `pickup_datetime` being 2013-01-01 while `dropoff_datetime` is 2013-01-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data_filtered_df = trip_data_df.filter(\n",
    "    (to_date(\"pickup_datetime\") == \"2013-01-01\") &\n",
    "    (to_date(\"dropoff_datetime\") == \"2013-01-01\")\n",
    ")\n",
    "\n",
    "trip_fare_filtered_df = trip_fare_df.filter(\n",
    "    (to_date(\"pickup_datetime\") == \"2013-01-01\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now merge the 2 dataframes using the `join` per `medallion`, `hack_license`, `vendor_id` and `pickup_datetime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_filtered_df = trip_data_filtered_df.join(\n",
    "    trip_fare_filtered_df,\n",
    "    on=[\"medallion\", \"hack_license\", \"vendor_id\", \"pickup_datetime\"],\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                        (0 + 10) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows are: 410816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"The number of rows are: {trip_filtered_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Provide a graphical representation to compare the average fare amount for trips _within_ and _across_ all the boroughs. You may want to have a look at: https://docs.bokeh.org/en/latest/docs/user_guide/topics/categorical.html#categorical-heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"f696bf9c-5590-4db4-8798-1c719ac76586\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"f696bf9c-5590-4db4-8798-1c719ac76586\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.7.2.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"f696bf9c-5590-4db4-8798-1c719ac76586\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "from pyspark.sql.functions import max as spark_max, min as spark_min\n",
    "\n",
    "from bokeh.plotting import figure, show, reset_output, output_notebook\n",
    "from bokeh.models import GeoJSONDataSource\n",
    "\n",
    "reset_output()\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_gdf = gpd.read_file('./data/nyc-boroughs.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trip_filtered_pd_df = trip_filtered_df.toPandas()\n",
    "\n",
    "pickup_gdf = gpd.GeoDataFrame(\n",
    "    trip_filtered_pd_df,\n",
    "    geometry=gpd.points_from_xy(trip_filtered_pd_df['pickup_longitude'], trip_filtered_pd_df['pickup_latitude']),\n",
    "    crs=borough_gdf.crs\n",
    ")\n",
    "\n",
    "dropoff_gdf = gpd.GeoDataFrame(\n",
    "    trip_filtered_pd_df,\n",
    "    geometry=gpd.points_from_xy(trip_filtered_pd_df['dropoff_longitude'], trip_filtered_pd_df['dropoff_latitude']),\n",
    "    crs=borough_gdf.crs\n",
    ")\n",
    "\n",
    "pickup_with_borough = gpd.sjoin(pickup_gdf, borough_gdf[['borough', 'geometry']], how='left', predicate='within')\n",
    "dropoff_with_borough = gpd.sjoin(dropoff_gdf, borough_gdf[['borough', 'geometry']], how='left', predicate='within')\n",
    "\n",
    "trip_filtered_pd_df['pickup_borough'] = pickup_with_borough['borough']\n",
    "trip_filtered_pd_df['dropoff_borough'] = dropoff_with_borough['borough']\n",
    "\n",
    "trip_filtered_df = spark.createDataFrame(trip_filtered_pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/06 22:51:19 WARN TaskSetManager: Stage 18 contains a task of very large size (8600 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/05/06 22:51:20 WARN TaskSetManager: Stage 24 contains a task of very large size (8600 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/05/06 22:51:21 WARN TaskSetManager: Stage 30 contains a task of very large size (8600 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"bb65ace0-091f-4d21-8d4b-d15992e037ce\" data-root-id=\"p1001\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"9917f2ee-4af3-4495-ae38-81be291d7cf2\":{\"version\":\"3.7.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1001\",\"attributes\":{\"width\":900,\"height\":400,\"x_range\":{\"type\":\"object\",\"name\":\"FactorRange\",\"id\":\"p1011\",\"attributes\":{\"factors\":[\"Staten Island\",\"Queens\",\"Brooklyn\",\"Manhattan\",\"Bronx\"]}},\"y_range\":{\"type\":\"object\",\"name\":\"FactorRange\",\"id\":\"p1012\",\"attributes\":{\"factors\":[\"Staten Island\",\"Queens\",\"Brooklyn\",\"Manhattan\",\"Bronx\"]}},\"x_scale\":{\"type\":\"object\",\"name\":\"CategoricalScale\",\"id\":\"p1013\"},\"y_scale\":{\"type\":\"object\",\"name\":\"CategoricalScale\",\"id\":\"p1014\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1004\",\"attributes\":{\"text\":\"Average Fare Amount for Pickup and Dropoff Boroughs\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1036\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1027\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1028\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1029\"},\"data\":{\"type\":\"map\",\"entries\":[[\"index\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAEAAAACAAAAAwAAAAQAAAAFAAAABgAAAAcAAAAIAAAACQAAAAoAAAALAAAADAAAAA0AAAAOAAAADwAAABAAAAARAAAAEgAAABMAAAAUAAAAFQAAABYAAAAXAAAAGAAAABkAAAAaAAAAGwAAABwAAAAdAAAAHgAAAB8AAAAgAAAA\"},\"shape\":[33],\"dtype\":\"int32\",\"order\":\"little\"}],[\"pickup_borough\",{\"type\":\"ndarray\",\"array\":[\"Brooklyn\",\"Brooklyn\",\"Manhattan\",\"NaN\",\"Queens\",\"Bronx\",\"Manhattan\",\"Queens\",\"Manhattan\",\"Manhattan\",\"Staten Island\",\"Bronx\",\"Bronx\",\"NaN\",\"NaN\",\"Brooklyn\",\"NaN\",\"Brooklyn\",\"Staten Island\",\"Queens\",\"Brooklyn\",\"NaN\",\"Manhattan\",\"Manhattan\",\"Queens\",\"Queens\",\"Brooklyn\",\"Queens\",\"Bronx\",\"Staten Island\",\"Bronx\",\"NaN\",\"Staten Island\"],\"shape\":[33],\"dtype\":\"object\",\"order\":\"little\"}],[\"dropoff_borough\",{\"type\":\"ndarray\",\"array\":[\"NaN\",\"Bronx\",\"Manhattan\",\"Manhattan\",\"Queens\",\"Queens\",\"NaN\",\"Staten Island\",\"Staten Island\",\"Brooklyn\",\"Manhattan\",\"Manhattan\",\"Bronx\",\"Bronx\",\"Brooklyn\",\"Manhattan\",\"Queens\",\"Brooklyn\",\"Brooklyn\",\"Bronx\",\"Queens\",\"NaN\",\"Queens\",\"Bronx\",\"Manhattan\",\"NaN\",\"Staten Island\",\"Brooklyn\",\"NaN\",\"Staten Island\",\"Brooklyn\",\"Staten Island\",\"NaN\"],\"shape\":[33],\"dtype\":\"object\",\"order\":\"little\"}],[\"avg_fare\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAAsQUCH8hrKayhHQCH0gp2e9SJAuBSf7uVYLkD/Rb8GKJMvQNPS0tLSUj5ApCk0nqLpSEDqTW960xtSQBdddNFF50pA/EqmB7koNkAAAAAAAHBCQPx2qSfj9zFAHFLRk9YtJkAUO7ETOzE6QAAAAAAAYD1AISji2CcRM0AndV8eW5E6QAICCDRmLiZAAAAAAAAANEBWkAMmQGxEQJFv2hdbGTlA8hzJwDn+MUDlAEDoOls9QO5TiuiY9DpAtQkp4XEAQUABodIfJp5KQAAAAAAAQEFAzgCfRJLKQUBddNFFF509QG/kRm7kxjlAAAAAAADgQ0AAAAAAAAAWQAAAAAAAAARA\"},\"shape\":[33],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1037\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1038\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Rect\",\"id\":\"p1033\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"pickup_borough\"},\"y\":{\"type\":\"field\",\"field\":\"dropoff_borough\"},\"width\":{\"type\":\"value\",\"value\":1},\"height\":{\"type\":\"value\",\"value\":1},\"line_color\":{\"type\":\"value\",\"value\":null},\"fill_color\":{\"type\":\"field\",\"field\":\"avg_fare\",\"transform\":{\"type\":\"object\",\"name\":\"LinearColorMapper\",\"id\":\"p1026\",\"attributes\":{\"palette\":[\"#caf0f8\",\"#ade8f4\",\"#90e0ef\",\"#48cae4\",\"#00b4d8\",\"#0096c7\",\"#0077b6\",\"#023e8a\",\"#03045e\"],\"low\":2.5,\"high\":72.43478260869566}}}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Rect\",\"id\":\"p1034\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"pickup_borough\"},\"y\":{\"type\":\"field\",\"field\":\"dropoff_borough\"},\"width\":{\"type\":\"value\",\"value\":1},\"height\":{\"type\":\"value\",\"value\":1},\"line_color\":{\"type\":\"value\",\"value\":null},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"field\",\"field\":\"avg_fare\",\"transform\":{\"id\":\"p1026\"}},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Rect\",\"id\":\"p1035\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"pickup_borough\"},\"y\":{\"type\":\"field\",\"field\":\"dropoff_borough\"},\"width\":{\"type\":\"value\",\"value\":1},\"height\":{\"type\":\"value\",\"value\":1},\"line_color\":{\"type\":\"value\",\"value\":null},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"field\",\"field\":\"avg_fare\",\"transform\":{\"id\":\"p1026\"}},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1010\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1025\",\"attributes\":{\"renderers\":\"auto\",\"tooltips\":[[\"Pickup Borough\",\"@pickup_borough\"],[\"Dropoff Borough\",\"@dropoff_borough\"],[\"Average Fare Amount\",\"@avg_fare{0.2f}\"]]}}]}},\"toolbar_location\":\"below\",\"left\":[{\"type\":\"object\",\"name\":\"CategoricalAxis\",\"id\":\"p1020\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"CategoricalTicker\",\"id\":\"p1021\"},\"formatter\":{\"type\":\"object\",\"name\":\"CategoricalTickFormatter\",\"id\":\"p1022\"},\"major_label_standoff\":0,\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1023\"},\"major_label_text_font_size\":\"7px\",\"axis_line_color\":null,\"major_tick_line_color\":null}}],\"right\":[{\"type\":\"object\",\"name\":\"ColorBar\",\"id\":\"p1041\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1039\",\"attributes\":{\"desired_num_ticks\":9,\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"PrintfTickFormatter\",\"id\":\"p1040\",\"attributes\":{\"format\":\"%d%%\"}},\"major_label_policy\":{\"type\":\"object\",\"name\":\"NoOverlap\",\"id\":\"p1042\"},\"padding\":5,\"major_label_text_font_size\":\"7px\",\"label_standoff\":6,\"color_mapper\":{\"id\":\"p1026\"}}}],\"above\":[{\"type\":\"object\",\"name\":\"CategoricalAxis\",\"id\":\"p1015\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"CategoricalTicker\",\"id\":\"p1016\"},\"formatter\":{\"type\":\"object\",\"name\":\"CategoricalTickFormatter\",\"id\":\"p1017\"},\"major_label_standoff\":0,\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1018\"},\"major_label_text_font_size\":\"7px\",\"axis_line_color\":null,\"major_tick_line_color\":null}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1019\",\"attributes\":{\"axis\":{\"id\":\"p1015\"},\"grid_line_color\":null}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1024\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1020\"},\"grid_line_color\":null}}]}}]}};\n  const render_items = [{\"docid\":\"9917f2ee-4af3-4495-ae38-81be291d7cf2\",\"roots\":{\"p1001\":\"bb65ace0-091f-4d21-8d4b-d15992e037ce\"},\"root_ids\":[\"p1001\"]}];\n  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p1001"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import BasicTicker, PrintfTickFormatter\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.transform import linear_cmap\n",
    "\n",
    "trip_group_df = trip_filtered_df \\\n",
    "    .groupBy(['pickup_borough', 'dropoff_borough']) \\\n",
    "    .avg('fare_amount') \\\n",
    "    .withColumnRenamed('avg(fare_amount)', 'avg_fare')\n",
    "\n",
    "pickup_borough = borough_gdf['borough'].unique()\n",
    "dropoff_borough = borough_gdf['borough'].unique()\n",
    "\n",
    "min = trip_group_df.agg(spark_min('avg_fare')).collect()[0][0]\n",
    "max = trip_group_df.agg(spark_max('avg_fare')).collect()[0][0]\n",
    "\n",
    "colors = [\"#03045e\", \"#023e8a\", \"#0077b6\", \"#0096c7\", \"#00b4d8\", \"#48cae4\", \"#90e0ef\", \"#ade8f4\", \"#caf0f8\"]\n",
    "\n",
    "TOOLS = \"hover\"\n",
    "TOOLTIPS = [\n",
    "    ('Pickup Borough', '@pickup_borough'),\n",
    "    ('Dropoff Borough', '@dropoff_borough'),\n",
    "    ('Average Fare Amount', '@avg_fare{0.2f}')\n",
    "]\n",
    "\n",
    "p = figure(title=\"Average Fare Amount for Pickup and Dropoff Boroughs\",\n",
    "           x_range=pickup_borough, y_range=dropoff_borough,\n",
    "           x_axis_location=\"above\", width=900, height=400,\n",
    "           tools=TOOLS, toolbar_location='below', tooltips=TOOLTIPS)\n",
    "\n",
    "p.grid.grid_line_color = None\n",
    "p.axis.axis_line_color = None\n",
    "p.axis.major_tick_line_color = None\n",
    "p.axis.major_label_text_font_size = \"7px\"\n",
    "p.axis.major_label_standoff = 0\n",
    "\n",
    "r = p.rect(x=\"pickup_borough\", y=\"dropoff_borough\", width=1, height=1, source=trip_group_df.toPandas(),\n",
    "           fill_color=linear_cmap(\"avg_fare\", colors[::-1], low=min, high=max),\n",
    "           line_color=None)\n",
    "\n",
    "p.add_layout(r.construct_color_bar(\n",
    "    major_label_text_font_size=\"7px\",\n",
    "    ticker=BasicTicker(desired_num_ticks=len(colors)),\n",
    "    formatter=PrintfTickFormatter(format=\"%d%%\"),\n",
    "    label_standoff=6,\n",
    "    border_line_color=None,\n",
    "    padding=5,\n",
    "), 'right')\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "Consider only Manhattan, Bronx and Brooklyn boroughs. Then create a dataframe that shows the total number of trips *within* the same borough and *across* all the other boroughs mentioned before (Manhattan, Bronx, and Brooklyn) where the passengers are more or equal than 3.\n",
    "\n",
    "For example, for Manhattan borough you should consider the total number of the following trips:\n",
    "- Manhattan → Manhattan\n",
    "- Manhattan → Bronx\n",
    "- Manhattan → Brooklyn\n",
    "\n",
    "You should then do the same for Bronx and Brooklyn boroughs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- medallion: string (nullable = true)\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- vendor_id: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- rate_code: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_time_in_secs: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- surcharge: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- pickup_borough: string (nullable = true)\n",
      " |-- dropoff_borough: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_filtered_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/06 22:51:21 WARN TaskSetManager: Stage 33 contains a task of very large size (8600 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/05/06 22:51:39 ERROR Executor: Exception in task 1.0 in stage 33.0 (TID 157)]\n",
      "java.net.SocketException: Connection reset\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:328)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)\n",
      "\tat java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)\n",
      "\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:244)\n",
      "\tat java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:284)\n",
      "\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:343)\n",
      "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:201)\n",
      "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:172)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:777)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "25/05/06 22:51:39 WARN TaskSetManager: Lost task 1.0 in stage 33.0 (TID 157) (192.168.43.129 executor driver): java.net.SocketException: Connection reset\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:328)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)\n",
      "\tat java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)\n",
      "\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:244)\n",
      "\tat java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:284)\n",
      "\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:343)\n",
      "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:201)\n",
      "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:172)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:777)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "\n",
      "25/05/06 22:51:39 ERROR TaskSetManager: Task 1 in stage 33.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o200.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 33.0 failed 1 times, most recent failure: Lost task 1.0 in stage 33.0 (TID 157) (192.168.43.129 executor driver): java.net.SocketException: Connection reset\n\tat java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:328)\n\tat java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)\n\tat java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)\n\tat java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)\n\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:244)\n\tat java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:284)\n\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:343)\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:201)\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:172)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:777)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:842)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: java.net.SocketException: Connection reset\n\tat java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:328)\n\tat java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)\n\tat java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)\n\tat java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)\n\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:244)\n\tat java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:284)\n\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:343)\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:201)\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:172)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:777)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages/IPython/core/formatters.py:770\u001b[39m, in \u001b[36mPlainTextFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    763\u001b[39m stream = StringIO()\n\u001b[32m    764\u001b[39m printer = pretty.RepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m.verbose,\n\u001b[32m    765\u001b[39m     \u001b[38;5;28mself\u001b[39m.max_width, \u001b[38;5;28mself\u001b[39m.newline,\n\u001b[32m    766\u001b[39m     max_seq_length=\u001b[38;5;28mself\u001b[39m.max_seq_length,\n\u001b[32m    767\u001b[39m     singleton_pprinters=\u001b[38;5;28mself\u001b[39m.singleton_printers,\n\u001b[32m    768\u001b[39m     type_pprinters=\u001b[38;5;28mself\u001b[39m.type_printers,\n\u001b[32m    769\u001b[39m     deferred_pprinters=\u001b[38;5;28mself\u001b[39m.deferred_printers)\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m \u001b[43mprinter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    771\u001b[39m printer.flush()\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stream.getvalue()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages/IPython/lib/pretty.py:411\u001b[39m, in \u001b[36mRepresentationPrinter.pretty\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    400\u001b[39m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[32m    401\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    402\u001b[39m                     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\n\u001b[32m    403\u001b[39m                     \u001b[38;5;66;03m# check if cls defines __repr__\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    409\u001b[39m                     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(_safe_getattr(\u001b[38;5;28mcls\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m__repr__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    410\u001b[39m                 ):\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages/IPython/lib/pretty.py:786\u001b[39m, in \u001b[36m_repr_pprint\u001b[39m\u001b[34m(obj, p, cycle)\u001b[39m\n\u001b[32m    784\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[32m    785\u001b[39m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m786\u001b[39m output = \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    787\u001b[39m lines = output.splitlines()\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m p.group():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages/pyspark/sql/dataframe.py:983\u001b[39m, in \u001b[36mDataFrame.__repr__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._support_repr_html \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sparkSession._jconf.isReplEagerEvalEnabled():\n\u001b[32m    982\u001b[39m     vertical = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparkSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplEagerEvalMaxNumRows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparkSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplEagerEvalTruncate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mDataFrame[\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m % (\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dtypes))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeco\u001b[39m(*a: Any, **kw: Any) -> Any:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    181\u001b[39m         converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages/py4j/protocol.py:326\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    324\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    331\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    332\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling o200.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 33.0 failed 1 times, most recent failure: Lost task 1.0 in stage 33.0 (TID 157) (192.168.43.129 executor driver): java.net.SocketException: Connection reset\n\tat java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:328)\n\tat java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)\n\tat java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)\n\tat java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)\n\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:244)\n\tat java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:284)\n\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:343)\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:201)\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:172)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:777)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:842)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: java.net.SocketException: Connection reset\n\tat java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:328)\n\tat java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)\n\tat java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)\n\tat java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)\n\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:244)\n\tat java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:284)\n\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:343)\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:201)\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:172)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:777)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:842)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/06 22:51:40 WARN TaskSetManager: Stage 34 contains a task of very large size (8600 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>pickup_borough</th><th>dropoff_borough</th><th>trip_count</th></tr>\n",
       "<tr><td>Manhattan</td><td>Manhattan</td><td>62391</td></tr>\n",
       "<tr><td>Manhattan</td><td>Brooklyn</td><td>2762</td></tr>\n",
       "<tr><td>Brooklyn</td><td>Brooklyn</td><td>2014</td></tr>\n",
       "<tr><td>Brooklyn</td><td>Manhattan</td><td>1326</td></tr>\n",
       "<tr><td>Manhattan</td><td>Bronx</td><td>527</td></tr>\n",
       "<tr><td>Bronx</td><td>Bronx</td><td>103</td></tr>\n",
       "<tr><td>Bronx</td><td>Manhattan</td><td>55</td></tr>\n",
       "<tr><td>Brooklyn</td><td>Bronx</td><td>10</td></tr>\n",
       "<tr><td>Bronx</td><td>Brooklyn</td><td>2</td></tr>\n",
       "</table>\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boroughs = ['Manhattan', 'Brooklyn', 'Bronx']\n",
    "min_passenger = 3\n",
    "\n",
    "trip_group_bp_df = trip_filtered_df \\\n",
    "    .filter(\n",
    "        (col('pickup_borough').isin(boroughs)) &\n",
    "        (col('dropoff_borough').isin(boroughs)) &\n",
    "        (col('passenger_count') >= min_passenger)\n",
    "    ) \\\n",
    "    .groupBy(['pickup_borough', 'dropoff_borough']) \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'trip_count') \\\n",
    "    .orderBy('trip_count', ascending=False)\n",
    "\n",
    "trip_group_bp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "Create a dataframe where each row represents a driver, and there is one column per borough.\n",
    "For each driver-borough, the dataframe provides the maximum number of consecutive trips\n",
    "for the given driver, within the given borough. Please consider only trips which were payed by card. \n",
    "\n",
    "For example, if for driver A we have (sorted by time):\n",
    "- Trip 1: Bronx → Bronx\n",
    "- Trip 2: Bronx → Bronx\n",
    "- Trip 3: Bronx → Manhattan\n",
    "- Trip 4: Manhattan → Bronx.\n",
    "    \n",
    "The maximum number of consecutive trips for Bronx is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/06 22:51:40 WARN TaskSetManager: Stage 37 contains a task of very large size (8600 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/05/06 22:51:44 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 37 (TID 177): Attempting to kill Python Worker\n",
      "25/05/06 22:51:45 WARN TaskSetManager: Stage 38 contains a task of very large size (8600 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>medallion</th><th>hack_license</th><th>vendor_id</th><th>pickup_datetime</th><th>rate_code</th><th>store_and_fwd_flag</th><th>dropoff_datetime</th><th>passenger_count</th><th>trip_time_in_secs</th><th>trip_distance</th><th>pickup_longitude</th><th>pickup_latitude</th><th>dropoff_longitude</th><th>dropoff_latitude</th><th>payment_type</th><th>fare_amount</th><th>surcharge</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>total_amount</th><th>pickup_borough</th><th>dropoff_borough</th></tr>\n",
       "<tr><td>00005007A9F30E289...</td><td>43468C5D35F828693...</td><td>CMT</td><td>2013-01-01 07:04:33</td><td>1</td><td>N</td><td>2013-01-01 07:16:03</td><td>1</td><td>689</td><td>3.1</td><td>-73.997002</td><td>40.732533</td><td>-73.970032</td><td>40.764423</td><td>CRD</td><td>12.0</td><td>0.0</td><td>0.5</td><td>2.5</td><td>0.0</td><td>15.0</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>00005007A9F30E289...</td><td>43468C5D35F828693...</td><td>CMT</td><td>2013-01-01 08:03:10</td><td>1</td><td>N</td><td>2013-01-01 08:06:41</td><td>1</td><td>211</td><td>1.3</td><td>-73.976471</td><td>40.743862</td><td>-73.985283</td><td>40.728035</td><td>CSH</td><td>6.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>6.5</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>00005007A9F30E289...</td><td>43468C5D35F828693...</td><td>CMT</td><td>2013-01-01 12:11:15</td><td>1</td><td>N</td><td>2013-01-01 12:26:47</td><td>1</td><td>931</td><td>8.3</td><td>-73.874786</td><td>40.774025</td><td>-73.970665</td><td>40.749886</td><td>CRD</td><td>24.0</td><td>0.0</td><td>0.5</td><td>5.86</td><td>4.8</td><td>35.16</td><td>Queens</td><td>Manhattan</td></tr>\n",
       "<tr><td>00005007A9F30E289...</td><td>43468C5D35F828693...</td><td>CMT</td><td>2013-01-01 14:01:48</td><td>1</td><td>N</td><td>2013-01-01 14:11:06</td><td>1</td><td>558</td><td>2.3</td><td>-73.953491</td><td>40.785721</td><td>-73.967339</td><td>40.759228</td><td>CSH</td><td>10.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>10.5</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>00005007A9F30E289...</td><td>A9AE329EA1138052D...</td><td>CMT</td><td>2013-01-01 02:43:02</td><td>1</td><td>N</td><td>2013-01-01 03:00:27</td><td>1</td><td>1045</td><td>3.7</td><td>-73.953056</td><td>40.78009</td><td>-73.993317</td><td>40.758999</td><td>CRD</td><td>15.5</td><td>0.5</td><td>0.5</td><td>3.3</td><td>0.0</td><td>19.8</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>00005007A9F30E289...</td><td>C72A773829ED990AF...</td><td>CMT</td><td>2013-01-01 18:33:03</td><td>1</td><td>N</td><td>2013-01-01 18:38:18</td><td>1</td><td>315</td><td>1.4</td><td>-73.958992</td><td>40.780998</td><td>-73.950035</td><td>40.795525</td><td>CSH</td><td>6.5</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>7.0</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>000318C2E3E638158...</td><td>91CE3B3A2F548CD8A...</td><td>VTS</td><td>2013-01-01 18:22:00</td><td>1</td><td>NULL</td><td>2013-01-01 18:27:00</td><td>5</td><td>300</td><td>1.17</td><td>-73.982239</td><td>40.773361</td><td>-73.991432</td><td>40.760235</td><td>CRD</td><td>6.0</td><td>0.0</td><td>0.5</td><td>1.5</td><td>0.0</td><td>8.0</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>000351EDC735C0792...</td><td>9413377237F83B3FE...</td><td>CMT</td><td>2013-01-01 02:02:24</td><td>1</td><td>N</td><td>2013-01-01 02:06:30</td><td>2</td><td>246</td><td>0.7</td><td>-73.946609</td><td>40.792274</td><td>-73.936211</td><td>40.794765</td><td>CSH</td><td>5.0</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>6.0</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>000351EDC735C0792...</td><td>9413377237F83B3FE...</td><td>CMT</td><td>2013-01-01 02:37:23</td><td>1</td><td>N</td><td>2013-01-01 02:39:21</td><td>2</td><td>118</td><td>0.4</td><td>-73.980286</td><td>40.751598</td><td>-73.974274</td><td>40.750317</td><td>CRD</td><td>3.5</td><td>0.5</td><td>0.5</td><td>3.0</td><td>0.0</td><td>7.5</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>0009986BDBAB2F9A1...</td><td>44CED38841518B1FB...</td><td>CMT</td><td>2013-01-01 01:10:38</td><td>1</td><td>N</td><td>2013-01-01 01:23:30</td><td>1</td><td>771</td><td>5.3</td><td>-73.950111</td><td>40.780079</td><td>-73.982079</td><td>40.722294</td><td>CSH</td><td>17.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>18.5</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>0009986BDBAB2F9A1...</td><td>44CED38841518B1FB...</td><td>CMT</td><td>2013-01-01 22:07:13</td><td>1</td><td>N</td><td>2013-01-01 22:11:57</td><td>1</td><td>283</td><td>1.7</td><td>-73.991547</td><td>40.749565</td><td>-73.998901</td><td>40.728062</td><td>CRD</td><td>7.0</td><td>0.5</td><td>0.5</td><td>1.6</td><td>0.0</td><td>9.6</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>0009986BDBAB2F9A1...</td><td>EB0BF47D51268910F...</td><td>CMT</td><td>2013-01-01 06:31:08</td><td>1</td><td>N</td><td>2013-01-01 06:36:03</td><td>1</td><td>295</td><td>2.1</td><td>-73.980927</td><td>40.782444</td><td>-73.990608</td><td>40.756325</td><td>CSH</td><td>8.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>8.5</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>00115F46520039845...</td><td>1F9C68FC8A7455B77...</td><td>CMT</td><td>2013-01-01 00:01:40</td><td>1</td><td>N</td><td>2013-01-01 00:12:28</td><td>1</td><td>648</td><td>3.0</td><td>-73.990479</td><td>40.686691</td><td>-73.992134</td><td>40.725365</td><td>CSH</td><td>12.0</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>13.0</td><td>Brooklyn</td><td>Manhattan</td></tr>\n",
       "<tr><td>00115F46520039845...</td><td>D15BCFC13719F28D7...</td><td>CMT</td><td>2013-01-01 15:52:14</td><td>1</td><td>N</td><td>2013-01-01 16:06:31</td><td>2</td><td>856</td><td>7.0</td><td>-74.016182</td><td>40.707844</td><td>-73.959404</td><td>40.766731</td><td>CRD</td><td>21.5</td><td>0.0</td><td>0.5</td><td>2.0</td><td>0.0</td><td>24.0</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>00115F46520039845...</td><td>D15BCFC13719F28D7...</td><td>CMT</td><td>2013-01-01 17:47:02</td><td>1</td><td>N</td><td>2013-01-01 17:50:28</td><td>3</td><td>205</td><td>0.5</td><td>-73.982918</td><td>40.756344</td><td>-73.978477</td><td>40.762554</td><td>CSH</td><td>4.5</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>5.0</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>00153E36140C5B2A8...</td><td>114A0835E3FCC3888...</td><td>VTS</td><td>2013-01-01 12:41:00</td><td>1</td><td>NULL</td><td>2013-01-01 12:43:00</td><td>2</td><td>120</td><td>0.22</td><td>-73.968704</td><td>40.764496</td><td>-73.970139</td><td>40.762329</td><td>CSH</td><td>3.5</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>4.0</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>001D3B86C2ACDEE4D...</td><td>F617CC84C553584DA...</td><td>CMT</td><td>2013-01-01 00:53:12</td><td>1</td><td>N</td><td>2013-01-01 01:12:09</td><td>1</td><td>1137</td><td>4.1</td><td>-74.005272</td><td>40.719395</td><td>-73.992973</td><td>40.768608</td><td>CRD</td><td>17.0</td><td>0.5</td><td>0.5</td><td>3.6</td><td>0.0</td><td>21.6</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>001D3B86C2ACDEE4D...</td><td>F617CC84C553584DA...</td><td>CMT</td><td>2013-01-01 03:48:11</td><td>1</td><td>N</td><td>2013-01-01 04:11:11</td><td>1</td><td>1379</td><td>6.7</td><td>-74.003632</td><td>40.72633</td><td>-73.92823</td><td>40.760124</td><td>CRD</td><td>22.5</td><td>0.5</td><td>0.5</td><td>4.7</td><td>0.0</td><td>28.2</td><td>Manhattan</td><td>Queens</td></tr>\n",
       "<tr><td>001D3B86C2ACDEE4D...</td><td>F617CC84C553584DA...</td><td>CMT</td><td>2013-01-01 04:45:10</td><td>1</td><td>N</td><td>2013-01-01 04:53:20</td><td>1</td><td>489</td><td>2.8</td><td>-73.987633</td><td>40.747406</td><td>-73.956207</td><td>40.768074</td><td>CSH</td><td>10.0</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>11.0</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>002B4CFC5B8920A87...</td><td>65938970D001F7280...</td><td>VTS</td><td>2013-01-01 15:31:00</td><td>1</td><td>NULL</td><td>2013-01-01 15:35:00</td><td>1</td><td>240</td><td>0.54</td><td>-73.98719</td><td>40.755932</td><td>-73.992805</td><td>40.753147</td><td>CSH</td><td>4.5</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>5.0</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------------------+--------------------+---------+-------------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+--------------+---------------+\n",
       "|           medallion|        hack_license|vendor_id|    pickup_datetime|rate_code|store_and_fwd_flag|   dropoff_datetime|passenger_count|trip_time_in_secs|trip_distance|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|surcharge|mta_tax|tip_amount|tolls_amount|total_amount|pickup_borough|dropoff_borough|\n",
       "+--------------------+--------------------+---------+-------------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+--------------+---------------+\n",
       "|00005007A9F30E289...|43468C5D35F828693...|      CMT|2013-01-01 07:04:33|        1|                 N|2013-01-01 07:16:03|              1|              689|          3.1|      -73.997002|      40.732533|       -73.970032|       40.764423|         CRD|       12.0|      0.0|    0.5|       2.5|         0.0|        15.0|     Manhattan|      Manhattan|\n",
       "|00005007A9F30E289...|43468C5D35F828693...|      CMT|2013-01-01 08:03:10|        1|                 N|2013-01-01 08:06:41|              1|              211|          1.3|      -73.976471|      40.743862|       -73.985283|       40.728035|         CSH|        6.0|      0.0|    0.5|       0.0|         0.0|         6.5|     Manhattan|      Manhattan|\n",
       "|00005007A9F30E289...|43468C5D35F828693...|      CMT|2013-01-01 12:11:15|        1|                 N|2013-01-01 12:26:47|              1|              931|          8.3|      -73.874786|      40.774025|       -73.970665|       40.749886|         CRD|       24.0|      0.0|    0.5|      5.86|         4.8|       35.16|        Queens|      Manhattan|\n",
       "|00005007A9F30E289...|43468C5D35F828693...|      CMT|2013-01-01 14:01:48|        1|                 N|2013-01-01 14:11:06|              1|              558|          2.3|      -73.953491|      40.785721|       -73.967339|       40.759228|         CSH|       10.0|      0.0|    0.5|       0.0|         0.0|        10.5|     Manhattan|      Manhattan|\n",
       "|00005007A9F30E289...|A9AE329EA1138052D...|      CMT|2013-01-01 02:43:02|        1|                 N|2013-01-01 03:00:27|              1|             1045|          3.7|      -73.953056|       40.78009|       -73.993317|       40.758999|         CRD|       15.5|      0.5|    0.5|       3.3|         0.0|        19.8|     Manhattan|      Manhattan|\n",
       "|00005007A9F30E289...|C72A773829ED990AF...|      CMT|2013-01-01 18:33:03|        1|                 N|2013-01-01 18:38:18|              1|              315|          1.4|      -73.958992|      40.780998|       -73.950035|       40.795525|         CSH|        6.5|      0.0|    0.5|       0.0|         0.0|         7.0|     Manhattan|      Manhattan|\n",
       "|000318C2E3E638158...|91CE3B3A2F548CD8A...|      VTS|2013-01-01 18:22:00|        1|              NULL|2013-01-01 18:27:00|              5|              300|         1.17|      -73.982239|      40.773361|       -73.991432|       40.760235|         CRD|        6.0|      0.0|    0.5|       1.5|         0.0|         8.0|     Manhattan|      Manhattan|\n",
       "|000351EDC735C0792...|9413377237F83B3FE...|      CMT|2013-01-01 02:02:24|        1|                 N|2013-01-01 02:06:30|              2|              246|          0.7|      -73.946609|      40.792274|       -73.936211|       40.794765|         CSH|        5.0|      0.5|    0.5|       0.0|         0.0|         6.0|     Manhattan|      Manhattan|\n",
       "|000351EDC735C0792...|9413377237F83B3FE...|      CMT|2013-01-01 02:37:23|        1|                 N|2013-01-01 02:39:21|              2|              118|          0.4|      -73.980286|      40.751598|       -73.974274|       40.750317|         CRD|        3.5|      0.5|    0.5|       3.0|         0.0|         7.5|     Manhattan|      Manhattan|\n",
       "|0009986BDBAB2F9A1...|44CED38841518B1FB...|      CMT|2013-01-01 01:10:38|        1|                 N|2013-01-01 01:23:30|              1|              771|          5.3|      -73.950111|      40.780079|       -73.982079|       40.722294|         CSH|       17.5|      0.5|    0.5|       0.0|         0.0|        18.5|     Manhattan|      Manhattan|\n",
       "|0009986BDBAB2F9A1...|44CED38841518B1FB...|      CMT|2013-01-01 22:07:13|        1|                 N|2013-01-01 22:11:57|              1|              283|          1.7|      -73.991547|      40.749565|       -73.998901|       40.728062|         CRD|        7.0|      0.5|    0.5|       1.6|         0.0|         9.6|     Manhattan|      Manhattan|\n",
       "|0009986BDBAB2F9A1...|EB0BF47D51268910F...|      CMT|2013-01-01 06:31:08|        1|                 N|2013-01-01 06:36:03|              1|              295|          2.1|      -73.980927|      40.782444|       -73.990608|       40.756325|         CSH|        8.0|      0.0|    0.5|       0.0|         0.0|         8.5|     Manhattan|      Manhattan|\n",
       "|00115F46520039845...|1F9C68FC8A7455B77...|      CMT|2013-01-01 00:01:40|        1|                 N|2013-01-01 00:12:28|              1|              648|          3.0|      -73.990479|      40.686691|       -73.992134|       40.725365|         CSH|       12.0|      0.5|    0.5|       0.0|         0.0|        13.0|      Brooklyn|      Manhattan|\n",
       "|00115F46520039845...|D15BCFC13719F28D7...|      CMT|2013-01-01 15:52:14|        1|                 N|2013-01-01 16:06:31|              2|              856|          7.0|      -74.016182|      40.707844|       -73.959404|       40.766731|         CRD|       21.5|      0.0|    0.5|       2.0|         0.0|        24.0|     Manhattan|      Manhattan|\n",
       "|00115F46520039845...|D15BCFC13719F28D7...|      CMT|2013-01-01 17:47:02|        1|                 N|2013-01-01 17:50:28|              3|              205|          0.5|      -73.982918|      40.756344|       -73.978477|       40.762554|         CSH|        4.5|      0.0|    0.5|       0.0|         0.0|         5.0|     Manhattan|      Manhattan|\n",
       "|00153E36140C5B2A8...|114A0835E3FCC3888...|      VTS|2013-01-01 12:41:00|        1|              NULL|2013-01-01 12:43:00|              2|              120|         0.22|      -73.968704|      40.764496|       -73.970139|       40.762329|         CSH|        3.5|      0.0|    0.5|       0.0|         0.0|         4.0|     Manhattan|      Manhattan|\n",
       "|001D3B86C2ACDEE4D...|F617CC84C553584DA...|      CMT|2013-01-01 00:53:12|        1|                 N|2013-01-01 01:12:09|              1|             1137|          4.1|      -74.005272|      40.719395|       -73.992973|       40.768608|         CRD|       17.0|      0.5|    0.5|       3.6|         0.0|        21.6|     Manhattan|      Manhattan|\n",
       "|001D3B86C2ACDEE4D...|F617CC84C553584DA...|      CMT|2013-01-01 03:48:11|        1|                 N|2013-01-01 04:11:11|              1|             1379|          6.7|      -74.003632|       40.72633|        -73.92823|       40.760124|         CRD|       22.5|      0.5|    0.5|       4.7|         0.0|        28.2|     Manhattan|         Queens|\n",
       "|001D3B86C2ACDEE4D...|F617CC84C553584DA...|      CMT|2013-01-01 04:45:10|        1|                 N|2013-01-01 04:53:20|              1|              489|          2.8|      -73.987633|      40.747406|       -73.956207|       40.768074|         CSH|       10.0|      0.5|    0.5|       0.0|         0.0|        11.0|     Manhattan|      Manhattan|\n",
       "|002B4CFC5B8920A87...|65938970D001F7280...|      VTS|2013-01-01 15:31:00|        1|              NULL|2013-01-01 15:35:00|              1|              240|         0.54|       -73.98719|      40.755932|       -73.992805|       40.753147|         CSH|        4.5|      0.0|    0.5|       0.0|         0.0|         5.0|     Manhattan|      Manhattan|\n",
       "+--------------------+--------------------+---------+-------------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+--------------+---------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/06 22:51:45 WARN TaskSetManager: Stage 39 contains a task of very large size (8600 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/05/06 22:51:45 WARN TaskSetManager: Stage 40 contains a task of very large size (8600 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>medallion</th><th>hack_license</th><th>vendor_id</th><th>pickup_datetime</th><th>rate_code</th><th>store_and_fwd_flag</th><th>dropoff_datetime</th><th>passenger_count</th><th>trip_time_in_secs</th><th>trip_distance</th><th>pickup_longitude</th><th>pickup_latitude</th><th>dropoff_longitude</th><th>dropoff_latitude</th><th>payment_type</th><th>fare_amount</th><th>surcharge</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>total_amount</th><th>pickup_borough</th><th>dropoff_borough</th></tr>\n",
       "<tr><td>BE530E79CB7E459DE...</td><td>0002555BBE359440D...</td><td>CMT</td><td>2013-01-01 19:00:00</td><td>1</td><td>N</td><td>2013-01-01 19:16:33</td><td>1</td><td>992</td><td>7.9</td><td>-73.885361</td><td>40.77314</td><td>-73.985107</td><td>40.745296</td><td>CRD</td><td>24.0</td><td>0.0</td><td>0.5</td><td>5.5</td><td>4.8</td><td>34.8</td><td>Queens</td><td>Manhattan</td></tr>\n",
       "<tr><td>BE530E79CB7E459DE...</td><td>0002555BBE359440D...</td><td>CMT</td><td>2013-01-01 19:52:35</td><td>1</td><td>N</td><td>2013-01-01 19:58:07</td><td>2</td><td>331</td><td>1.5</td><td>-73.973091</td><td>40.748756</td><td>-73.984703</td><td>40.72897</td><td>CRD</td><td>7.0</td><td>0.0</td><td>0.5</td><td>1.5</td><td>0.0</td><td>9.0</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>BE530E79CB7E459DE...</td><td>0002555BBE359440D...</td><td>CMT</td><td>2013-01-01 19:59:25</td><td>1</td><td>N</td><td>2013-01-01 20:07:57</td><td>2</td><td>512</td><td>2.2</td><td>-73.984062</td><td>40.72908</td><td>-73.981079</td><td>40.753746</td><td>CSH</td><td>9.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>9.5</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>BE530E79CB7E459DE...</td><td>0002555BBE359440D...</td><td>CMT</td><td>2013-01-01 20:15:23</td><td>1</td><td>N</td><td>2013-01-01 20:26:49</td><td>3</td><td>685</td><td>1.0</td><td>-73.975067</td><td>40.765324</td><td>-73.985733</td><td>40.755859</td><td>CSH</td><td>8.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>9.5</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>BE530E79CB7E459DE...</td><td>0002555BBE359440D...</td><td>CMT</td><td>2013-01-01 20:52:23</td><td>1</td><td>N</td><td>2013-01-01 20:58:23</td><td>2</td><td>360</td><td>1.6</td><td>-73.995766</td><td>40.754169</td><td>-74.003349</td><td>40.732578</td><td>CSH</td><td>7.0</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>8.0</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>BE530E79CB7E459DE...</td><td>0002555BBE359440D...</td><td>CMT</td><td>2013-01-01 21:23:24</td><td>1</td><td>N</td><td>2013-01-01 21:40:06</td><td>1</td><td>1001</td><td>9.2</td><td>-73.885406</td><td>40.773132</td><td>-73.983795</td><td>40.729431</td><td>CRD</td><td>27.0</td><td>0.5</td><td>0.5</td><td>8.4</td><td>0.0</td><td>36.4</td><td>Queens</td><td>Manhattan</td></tr>\n",
       "<tr><td>BE530E79CB7E459DE...</td><td>0002555BBE359440D...</td><td>CMT</td><td>2013-01-01 21:47:40</td><td>1</td><td>N</td><td>2013-01-01 21:57:05</td><td>1</td><td>564</td><td>4.2</td><td>-73.988541</td><td>40.720161</td><td>-73.955399</td><td>40.772987</td><td>CSH</td><td>13.0</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>14.0</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>BE530E79CB7E459DE...</td><td>0002555BBE359440D...</td><td>CMT</td><td>2013-01-01 23:01:07</td><td>1</td><td>N</td><td>2013-01-01 23:05:41</td><td>2</td><td>273</td><td>1.7</td><td>-73.862869</td><td>40.768734</td><td>-73.866905</td><td>40.767513</td><td>CRD</td><td>7.0</td><td>0.5</td><td>0.5</td><td>1.0</td><td>0.0</td><td>9.0</td><td>Queens</td><td>Queens</td></tr>\n",
       "<tr><td>BE530E79CB7E459DE...</td><td>0002555BBE359440D...</td><td>CMT</td><td>2013-01-01 23:40:33</td><td>1</td><td>N</td><td>2013-01-01 23:53:54</td><td>1</td><td>801</td><td>7.5</td><td>-73.873032</td><td>40.774212</td><td>-73.944611</td><td>40.780037</td><td>CRD</td><td>22.0</td><td>0.5</td><td>0.5</td><td>5.0</td><td>4.8</td><td>32.8</td><td>Queens</td><td>Manhattan</td></tr>\n",
       "<tr><td>515D614B20D2BF3BE...</td><td>000A4EBF1CEB9C6BD...</td><td>CMT</td><td>2013-01-01 18:09:09</td><td>1</td><td>N</td><td>2013-01-01 18:15:36</td><td>1</td><td>386</td><td>0.9</td><td>-74.014488</td><td>40.715797</td><td>-74.004692</td><td>40.71751</td><td>CSH</td><td>6.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>6.5</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>515D614B20D2BF3BE...</td><td>000A4EBF1CEB9C6BD...</td><td>CMT</td><td>2013-01-01 18:23:39</td><td>1</td><td>N</td><td>2013-01-01 18:44:25</td><td>2</td><td>1246</td><td>7.7</td><td>-73.996956</td><td>40.737206</td><td>-73.948814</td><td>40.809086</td><td>CSH</td><td>25.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>25.5</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>515D614B20D2BF3BE...</td><td>000A4EBF1CEB9C6BD...</td><td>CMT</td><td>2013-01-01 18:48:50</td><td>1</td><td>N</td><td>2013-01-01 18:56:14</td><td>1</td><td>444</td><td>1.2</td><td>-73.954529</td><td>40.80056</td><td>-73.949631</td><td>40.787663</td><td>CSH</td><td>7.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>7.5</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>515D614B20D2BF3BE...</td><td>000A4EBF1CEB9C6BD...</td><td>CMT</td><td>2013-01-01 19:15:31</td><td>1</td><td>N</td><td>2013-01-01 19:35:05</td><td>1</td><td>1174</td><td>7.6</td><td>-73.954231</td><td>40.764126</td><td>-73.994972</td><td>40.690418</td><td>CRD</td><td>23.5</td><td>0.0</td><td>0.5</td><td>3.0</td><td>0.0</td><td>27.0</td><td>Manhattan</td><td>Brooklyn</td></tr>\n",
       "<tr><td>515D614B20D2BF3BE...</td><td>000A4EBF1CEB9C6BD...</td><td>CMT</td><td>2013-01-01 19:36:35</td><td>1</td><td>N</td><td>2013-01-01 19:47:04</td><td>3</td><td>629</td><td>5.2</td><td>-73.994949</td><td>40.690384</td><td>-73.964371</td><td>40.712662</td><td>CRD</td><td>15.5</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>16.0</td><td>Brooklyn</td><td>Brooklyn</td></tr>\n",
       "<tr><td>515D614B20D2BF3BE...</td><td>000A4EBF1CEB9C6BD...</td><td>CMT</td><td>2013-01-01 19:50:11</td><td>1</td><td>N</td><td>2013-01-01 19:55:25</td><td>2</td><td>313</td><td>0.9</td><td>-73.960815</td><td>40.714943</td><td>-73.945839</td><td>40.718716</td><td>CSH</td><td>6.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>6.5</td><td>Brooklyn</td><td>Brooklyn</td></tr>\n",
       "<tr><td>515D614B20D2BF3BE...</td><td>000A4EBF1CEB9C6BD...</td><td>CMT</td><td>2013-01-01 20:34:58</td><td>1</td><td>N</td><td>2013-01-01 20:59:57</td><td>3</td><td>1499</td><td>17.3</td><td>-73.864128</td><td>40.769657</td><td>-74.030685</td><td>40.627403</td><td>CSH</td><td>46.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>47.5</td><td>Queens</td><td>Brooklyn</td></tr>\n",
       "<tr><td>515D614B20D2BF3BE...</td><td>000A4EBF1CEB9C6BD...</td><td>CMT</td><td>2013-01-01 21:35:25</td><td>1</td><td>N</td><td>2013-01-01 21:58:23</td><td>1</td><td>1377</td><td>9.2</td><td>-73.873047</td><td>40.774151</td><td>-73.992577</td><td>40.756699</td><td>CRD</td><td>29.0</td><td>0.5</td><td>0.5</td><td>6.95</td><td>4.8</td><td>41.75</td><td>Queens</td><td>Manhattan</td></tr>\n",
       "<tr><td>515D614B20D2BF3BE...</td><td>000A4EBF1CEB9C6BD...</td><td>CMT</td><td>2013-01-01 22:27:53</td><td>1</td><td>N</td><td>2013-01-01 22:39:50</td><td>1</td><td>717</td><td>3.1</td><td>-73.977608</td><td>40.75275</td><td>-73.973961</td><td>40.789089</td><td>CSH</td><td>12.0</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>13.0</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>515D614B20D2BF3BE...</td><td>000A4EBF1CEB9C6BD...</td><td>CMT</td><td>2013-01-01 22:58:31</td><td>1</td><td>N</td><td>2013-01-01 23:18:31</td><td>1</td><td>1200</td><td>6.3</td><td>-74.000107</td><td>40.748466</td><td>-73.922791</td><td>40.766529</td><td>CRD</td><td>20.5</td><td>0.5</td><td>0.5</td><td>4.3</td><td>0.0</td><td>25.8</td><td>Manhattan</td><td>Queens</td></tr>\n",
       "<tr><td>DC1BD2B0B0BE3A651...</td><td>000B8D660A329BBDB...</td><td>CMT</td><td>2013-01-01 00:04:27</td><td>1</td><td>N</td><td>2013-01-01 00:11:20</td><td>1</td><td>413</td><td>2.3</td><td>-73.979118</td><td>40.762318</td><td>-73.950272</td><td>40.771259</td><td>CRD</td><td>8.5</td><td>0.5</td><td>0.5</td><td>2.37</td><td>0.0</td><td>11.87</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------------------+--------------------+---------+-------------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+--------------+---------------+\n",
       "|           medallion|        hack_license|vendor_id|    pickup_datetime|rate_code|store_and_fwd_flag|   dropoff_datetime|passenger_count|trip_time_in_secs|trip_distance|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|surcharge|mta_tax|tip_amount|tolls_amount|total_amount|pickup_borough|dropoff_borough|\n",
       "+--------------------+--------------------+---------+-------------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+--------------+---------------+\n",
       "|BE530E79CB7E459DE...|0002555BBE359440D...|      CMT|2013-01-01 19:00:00|        1|                 N|2013-01-01 19:16:33|              1|              992|          7.9|      -73.885361|       40.77314|       -73.985107|       40.745296|         CRD|       24.0|      0.0|    0.5|       5.5|         4.8|        34.8|        Queens|      Manhattan|\n",
       "|BE530E79CB7E459DE...|0002555BBE359440D...|      CMT|2013-01-01 19:52:35|        1|                 N|2013-01-01 19:58:07|              2|              331|          1.5|      -73.973091|      40.748756|       -73.984703|        40.72897|         CRD|        7.0|      0.0|    0.5|       1.5|         0.0|         9.0|     Manhattan|      Manhattan|\n",
       "|BE530E79CB7E459DE...|0002555BBE359440D...|      CMT|2013-01-01 19:59:25|        1|                 N|2013-01-01 20:07:57|              2|              512|          2.2|      -73.984062|       40.72908|       -73.981079|       40.753746|         CSH|        9.0|      0.0|    0.5|       0.0|         0.0|         9.5|     Manhattan|      Manhattan|\n",
       "|BE530E79CB7E459DE...|0002555BBE359440D...|      CMT|2013-01-01 20:15:23|        1|                 N|2013-01-01 20:26:49|              3|              685|          1.0|      -73.975067|      40.765324|       -73.985733|       40.755859|         CSH|        8.5|      0.5|    0.5|       0.0|         0.0|         9.5|     Manhattan|      Manhattan|\n",
       "|BE530E79CB7E459DE...|0002555BBE359440D...|      CMT|2013-01-01 20:52:23|        1|                 N|2013-01-01 20:58:23|              2|              360|          1.6|      -73.995766|      40.754169|       -74.003349|       40.732578|         CSH|        7.0|      0.5|    0.5|       0.0|         0.0|         8.0|     Manhattan|      Manhattan|\n",
       "|BE530E79CB7E459DE...|0002555BBE359440D...|      CMT|2013-01-01 21:23:24|        1|                 N|2013-01-01 21:40:06|              1|             1001|          9.2|      -73.885406|      40.773132|       -73.983795|       40.729431|         CRD|       27.0|      0.5|    0.5|       8.4|         0.0|        36.4|        Queens|      Manhattan|\n",
       "|BE530E79CB7E459DE...|0002555BBE359440D...|      CMT|2013-01-01 21:47:40|        1|                 N|2013-01-01 21:57:05|              1|              564|          4.2|      -73.988541|      40.720161|       -73.955399|       40.772987|         CSH|       13.0|      0.5|    0.5|       0.0|         0.0|        14.0|     Manhattan|      Manhattan|\n",
       "|BE530E79CB7E459DE...|0002555BBE359440D...|      CMT|2013-01-01 23:01:07|        1|                 N|2013-01-01 23:05:41|              2|              273|          1.7|      -73.862869|      40.768734|       -73.866905|       40.767513|         CRD|        7.0|      0.5|    0.5|       1.0|         0.0|         9.0|        Queens|         Queens|\n",
       "|BE530E79CB7E459DE...|0002555BBE359440D...|      CMT|2013-01-01 23:40:33|        1|                 N|2013-01-01 23:53:54|              1|              801|          7.5|      -73.873032|      40.774212|       -73.944611|       40.780037|         CRD|       22.0|      0.5|    0.5|       5.0|         4.8|        32.8|        Queens|      Manhattan|\n",
       "|515D614B20D2BF3BE...|000A4EBF1CEB9C6BD...|      CMT|2013-01-01 18:09:09|        1|                 N|2013-01-01 18:15:36|              1|              386|          0.9|      -74.014488|      40.715797|       -74.004692|        40.71751|         CSH|        6.0|      0.0|    0.5|       0.0|         0.0|         6.5|     Manhattan|      Manhattan|\n",
       "|515D614B20D2BF3BE...|000A4EBF1CEB9C6BD...|      CMT|2013-01-01 18:23:39|        1|                 N|2013-01-01 18:44:25|              2|             1246|          7.7|      -73.996956|      40.737206|       -73.948814|       40.809086|         CSH|       25.0|      0.0|    0.5|       0.0|         0.0|        25.5|     Manhattan|      Manhattan|\n",
       "|515D614B20D2BF3BE...|000A4EBF1CEB9C6BD...|      CMT|2013-01-01 18:48:50|        1|                 N|2013-01-01 18:56:14|              1|              444|          1.2|      -73.954529|       40.80056|       -73.949631|       40.787663|         CSH|        7.0|      0.0|    0.5|       0.0|         0.0|         7.5|     Manhattan|      Manhattan|\n",
       "|515D614B20D2BF3BE...|000A4EBF1CEB9C6BD...|      CMT|2013-01-01 19:15:31|        1|                 N|2013-01-01 19:35:05|              1|             1174|          7.6|      -73.954231|      40.764126|       -73.994972|       40.690418|         CRD|       23.5|      0.0|    0.5|       3.0|         0.0|        27.0|     Manhattan|       Brooklyn|\n",
       "|515D614B20D2BF3BE...|000A4EBF1CEB9C6BD...|      CMT|2013-01-01 19:36:35|        1|                 N|2013-01-01 19:47:04|              3|              629|          5.2|      -73.994949|      40.690384|       -73.964371|       40.712662|         CRD|       15.5|      0.0|    0.5|       0.0|         0.0|        16.0|      Brooklyn|       Brooklyn|\n",
       "|515D614B20D2BF3BE...|000A4EBF1CEB9C6BD...|      CMT|2013-01-01 19:50:11|        1|                 N|2013-01-01 19:55:25|              2|              313|          0.9|      -73.960815|      40.714943|       -73.945839|       40.718716|         CSH|        6.0|      0.0|    0.5|       0.0|         0.0|         6.5|      Brooklyn|       Brooklyn|\n",
       "|515D614B20D2BF3BE...|000A4EBF1CEB9C6BD...|      CMT|2013-01-01 20:34:58|        1|                 N|2013-01-01 20:59:57|              3|             1499|         17.3|      -73.864128|      40.769657|       -74.030685|       40.627403|         CSH|       46.5|      0.5|    0.5|       0.0|         0.0|        47.5|        Queens|       Brooklyn|\n",
       "|515D614B20D2BF3BE...|000A4EBF1CEB9C6BD...|      CMT|2013-01-01 21:35:25|        1|                 N|2013-01-01 21:58:23|              1|             1377|          9.2|      -73.873047|      40.774151|       -73.992577|       40.756699|         CRD|       29.0|      0.5|    0.5|      6.95|         4.8|       41.75|        Queens|      Manhattan|\n",
       "|515D614B20D2BF3BE...|000A4EBF1CEB9C6BD...|      CMT|2013-01-01 22:27:53|        1|                 N|2013-01-01 22:39:50|              1|              717|          3.1|      -73.977608|       40.75275|       -73.973961|       40.789089|         CSH|       12.0|      0.5|    0.5|       0.0|         0.0|        13.0|     Manhattan|      Manhattan|\n",
       "|515D614B20D2BF3BE...|000A4EBF1CEB9C6BD...|      CMT|2013-01-01 22:58:31|        1|                 N|2013-01-01 23:18:31|              1|             1200|          6.3|      -74.000107|      40.748466|       -73.922791|       40.766529|         CRD|       20.5|      0.5|    0.5|       4.3|         0.0|        25.8|     Manhattan|         Queens|\n",
       "|DC1BD2B0B0BE3A651...|000B8D660A329BBDB...|      CMT|2013-01-01 00:04:27|        1|                 N|2013-01-01 00:11:20|              1|              413|          2.3|      -73.979118|      40.762318|       -73.950272|       40.771259|         CRD|        8.5|      0.5|    0.5|      2.37|         0.0|       11.87|     Manhattan|      Manhattan|\n",
       "+--------------------+--------------------+---------+-------------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+--------------+---------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_filtered_df = trip_filtered_df.sort(['hack_license', 'pickup_datetime'], ascending=True)\n",
    "trip_filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/jtclhl4538l1681zfsfm7y680000gp/T/ipykernel_15141/300284578.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trip_drivers_df['condition'] = condition\n",
      "/var/folders/xz/jtclhl4538l1681zfsfm7y680000gp/T/ipykernel_15141/300284578.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trip_drivers_df['condition'] = condition\n",
      "/var/folders/xz/jtclhl4538l1681zfsfm7y680000gp/T/ipykernel_15141/300284578.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trip_drivers_df['condition'] = condition\n",
      "/var/folders/xz/jtclhl4538l1681zfsfm7y680000gp/T/ipykernel_15141/300284578.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trip_drivers_df['condition'] = condition\n",
      "/var/folders/xz/jtclhl4538l1681zfsfm7y680000gp/T/ipykernel_15141/300284578.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trip_drivers_df['condition'] = condition\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hack_license</th>\n",
       "      <th>pickup_borough</th>\n",
       "      <th>dropoff_borough</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43468C5D35F828693D96CB7CC9FDF341</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>CRD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43468C5D35F828693D96CB7CC9FDF341</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>CSH</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43468C5D35F828693D96CB7CC9FDF341</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>CRD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43468C5D35F828693D96CB7CC9FDF341</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>CSH</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A9AE329EA1138052DAC8FDFD8BA86603</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>CRD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410811</th>\n",
       "      <td>E63C65190C8631169C32E03736965EB1</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>CRD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410812</th>\n",
       "      <td>02182B348E0AD9B1332DB0F799D53A2C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSH</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410813</th>\n",
       "      <td>152770A91DC9D866E5BD97B472A578BE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSH</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410814</th>\n",
       "      <td>297FBB63FE6223D1F61C13CF32D2682B</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>CSH</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410815</th>\n",
       "      <td>648659963B4639CA17884B391333A9C3</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>CRD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410816 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            hack_license pickup_borough dropoff_borough  \\\n",
       "0       43468C5D35F828693D96CB7CC9FDF341      Manhattan       Manhattan   \n",
       "1       43468C5D35F828693D96CB7CC9FDF341      Manhattan       Manhattan   \n",
       "2       43468C5D35F828693D96CB7CC9FDF341         Queens       Manhattan   \n",
       "3       43468C5D35F828693D96CB7CC9FDF341      Manhattan       Manhattan   \n",
       "4       A9AE329EA1138052DAC8FDFD8BA86603      Manhattan       Manhattan   \n",
       "...                                  ...            ...             ...   \n",
       "410811  E63C65190C8631169C32E03736965EB1      Manhattan       Manhattan   \n",
       "410812  02182B348E0AD9B1332DB0F799D53A2C            NaN             NaN   \n",
       "410813  152770A91DC9D866E5BD97B472A578BE            NaN             NaN   \n",
       "410814  297FBB63FE6223D1F61C13CF32D2682B      Manhattan       Manhattan   \n",
       "410815  648659963B4639CA17884B391333A9C3         Queens        Brooklyn   \n",
       "\n",
       "       payment_type  condition  \n",
       "0               CRD      False  \n",
       "1               CSH      False  \n",
       "2               CRD      False  \n",
       "3               CSH      False  \n",
       "4               CRD      False  \n",
       "...             ...        ...  \n",
       "410811          CRD      False  \n",
       "410812          CSH      False  \n",
       "410813          CSH      False  \n",
       "410814          CSH      False  \n",
       "410815          CRD      False  \n",
       "\n",
       "[410816 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure the correct columns are selected\n",
    "trip_drivers_df = trip_filtered_pd_df[['hack_license', 'pickup_borough', 'dropoff_borough', 'payment_type']]\n",
    "boroughs = borough_gdf['borough'].unique()\n",
    "payment = 'CRD'\n",
    "\n",
    "# Result dictionary to hold per-borough max consecutive Trues per driver\n",
    "result = {}\n",
    "\n",
    "for borough in boroughs:\n",
    "    # Step 1: Apply the filters\n",
    "    pickup_filter = trip_drivers_df['pickup_borough'] == borough\n",
    "    dropoff_filter = trip_drivers_df['dropoff_borough'] == borough\n",
    "    payment_filter = trip_drivers_df['payment_type'] == payment\n",
    "    condition = pickup_filter & dropoff_filter & payment_filter\n",
    "\n",
    "    # Step 2: Add a temporary column for this condition\n",
    "    trip_drivers_df['condition'] = condition\n",
    "\n",
    "    # Step 3: Group by hack_license and calculate max consecutive True\n",
    "    def max_consecutive_trues(s):\n",
    "        return s.groupby((~s).cumsum()).sum().max()\n",
    "\n",
    "    max_streaks = trip_drivers_df.groupby('hack_license')['condition'].apply(max_consecutive_trues)\n",
    "\n",
    "    # Store result\n",
    "    result[borough] = max_streaks\n",
    "\n",
    "# `result` is now a dictionary where each key is a borough and each value is a Series of max streaks per driver.\n",
    "\n",
    "trip_drivers_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Please work on the merged dataset of trips and fares and perform the following data cleaning tasks:\n",
    "\n",
    "1. Remove trips with invalid locations (i.e. not in New York City);\n",
    "3. Remove trips with invalid amounts:\n",
    "    - Total amount must be greater than zero;\n",
    "    - Total amount must correspond to the sum of all the other amounts.\n",
    "5. Remove trips with invalid time:\n",
    "    - Pick-up before drop-off;\n",
    "    - Valid duration.\n",
    "\n",
    "After each data cleaning task, report how many rows where removed. Finally report:\n",
    "- Are there **duplicate trips**?\n",
    "- How many trips remain after cleaning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chardet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpolars\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpl\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchardet\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'chardet'"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding: ascii\n"
     ]
    }
   ],
   "source": [
    "with open('data/trip_fare.csv', 'rb') as f:\n",
    "    data = f.read()\n",
    "\n",
    "encoding_result = chardet.detect(data)\n",
    "encoding = encoding_result['encoding']\n",
    "print(f\"Detected encoding: {encoding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "could not parse `1.75` as dtype `i64` at column ' tip_amount' (column number 9)\n\nThe current offset in the file is 17600 bytes.\n\nYou might want to try:\n- increasing `infer_schema_length` (e.g. `infer_schema_length=10000`),\n- specifying correct dtype with the `schema_overrides` argument\n- setting `ignore_errors` to `True`,\n- adding `1.75` to the `null_values` list.\n\nOriginal error: ```remaining bytes non-empty```",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mComputeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m tripdata_polar_df = pl.read_csv(\u001b[33m'\u001b[39m\u001b[33m./data/trip_data.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m tripfare_polar_df = \u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./data/trip_fare.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages/polars/_utils/deprecation.py:119\u001b[39m, in \u001b[36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> T:\n\u001b[32m    116\u001b[39m     _rename_keyword_argument(\n\u001b[32m    117\u001b[39m         old_name, new_name, kwargs, function.\u001b[34m__qualname__\u001b[39m, version\n\u001b[32m    118\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages/polars/_utils/deprecation.py:119\u001b[39m, in \u001b[36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> T:\n\u001b[32m    116\u001b[39m     _rename_keyword_argument(\n\u001b[32m    117\u001b[39m         old_name, new_name, kwargs, function.\u001b[34m__qualname__\u001b[39m, version\n\u001b[32m    118\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages/polars/_utils/deprecation.py:119\u001b[39m, in \u001b[36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> T:\n\u001b[32m    116\u001b[39m     _rename_keyword_argument(\n\u001b[32m    117\u001b[39m         old_name, new_name, kwargs, function.\u001b[34m__qualname__\u001b[39m, version\n\u001b[32m    118\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages/polars/io/csv/functions.py:539\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(source, has_header, columns, new_columns, separator, comment_prefix, quote_char, skip_rows, skip_lines, schema, schema_overrides, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, use_pyarrow, storage_options, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines, decimal_comma, glob)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m prepare_file_arg(\n\u001b[32m    533\u001b[39m         source,\n\u001b[32m    534\u001b[39m         encoding=encoding,\n\u001b[32m   (...)\u001b[39m\u001b[32m    537\u001b[39m         storage_options=storage_options,\n\u001b[32m    538\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m         df = \u001b[43m_read_csv_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprojection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m            \u001b[49m\u001b[43mseparator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcomment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m            \u001b[49m\u001b[43mquote_char\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquote_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m            \u001b[49m\u001b[43mskip_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m            \u001b[49m\u001b[43mskip_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnull_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnull_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmissing_utf8_is_empty_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_utf8_is_empty_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m            \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtry_parse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtry_parse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m            \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf8-lossy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrechunk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrechunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m            \u001b[49m\u001b[43mskip_rows_after_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_rows_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrow_index_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow_index_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrow_index_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow_index_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m            \u001b[49m\u001b[43meol_char\u001b[49m\u001b[43m=\u001b[49m\u001b[43meol_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m            \u001b[49m\u001b[43mraise_if_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraise_if_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdecimal_comma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal_comma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m            \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m=\u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_columns:\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _update_columns(df, new_columns)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/VS-assignment3/lib/python3.12/site-packages/polars/io/csv/functions.py:687\u001b[39m, in \u001b[36m_read_csv_impl\u001b[39m\u001b[34m(source, has_header, columns, separator, comment_prefix, quote_char, skip_rows, skip_lines, schema, schema_overrides, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines, decimal_comma, glob)\u001b[39m\n\u001b[32m    683\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    685\u001b[39m projection, columns = parse_columns_arg(columns)\n\u001b[32m--> \u001b[39m\u001b[32m687\u001b[39m pydf = \u001b[43mPyDataFrame\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprojection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrechunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquote_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprocessed_null_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmissing_utf8_is_empty_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtry_parse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_rows_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparse_row_index_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_index_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_index_offset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m    \u001b[49m\u001b[43meol_char\u001b[49m\u001b[43m=\u001b[49m\u001b[43meol_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraise_if_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraise_if_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecimal_comma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal_comma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(pydf)\n",
      "\u001b[31mComputeError\u001b[39m: could not parse `1.75` as dtype `i64` at column ' tip_amount' (column number 9)\n\nThe current offset in the file is 17600 bytes.\n\nYou might want to try:\n- increasing `infer_schema_length` (e.g. `infer_schema_length=10000`),\n- specifying correct dtype with the `schema_overrides` argument\n- setting `ignore_errors` to `True`,\n- adding `1.75` to the `null_values` list.\n\nOriginal error: ```remaining bytes non-empty```"
     ]
    }
   ],
   "source": [
    "tripdata_polar_df = pl.read_csv('./data/trip_data.csv')\n",
    "tripfare_polar_df = pl.read_csv('./data/trip_fare.csv', encoding=encoding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Compute the **total revenue** (total_amount) grouped by:\n",
    "- Pick-up hour of the day (0–23)\n",
    "- Passenger count (group >=6 into “6+”)\n",
    "\n",
    "Create a heatmap where:\n",
    "- X-axis = hour\n",
    "- Y-axis = passenger count group\n",
    "- Cell value = average revenue per trip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "Define an \"anomalous trip\" as one that satisfies at least two of the following:\n",
    "- Fare per mile is above the 95th percentile\n",
    "- Tip amount > 100% of fare\n",
    "- trip_time_in_secs is less than 60 seconds but distance is more than 1 mile\n",
    "\n",
    "Create a dataframe of anomalous trips and:\n",
    "- Report how many such trips exist\n",
    "- Create a scatterplot to visualize the anomaly metrics\n",
    "- Describe the visualization identifying groups and outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "For each driver (hack_license), calculate the **total profit per hour worked**, where:\n",
    "> profit = 0.7 * (fare_amount + tip_amount) when the trip starts between 7:01 AM and 7:00 PM\\\n",
    "> profit = 0.8 * (fare_amount + tip_amount) when the trip starts between 7:01PM and 7:00 AM\n",
    "\n",
    "Estimate \"hours worked\" by summing trip_time_in_secs.\n",
    "\n",
    "Plot a line chart showing the distribution of average profit per hour **for the top 10% drivers** in terms of total trips.\n",
    "\n",
    "Which time of day offers **best earning efficiency**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
